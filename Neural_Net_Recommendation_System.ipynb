{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Net Recommendation System.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "F7Q5a07Zzhyr",
        "2jijXH5dzuam"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMMILztTyqXN",
        "colab_type": "text"
      },
      "source": [
        "## Mounting Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agoc9KJJFNhO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "abdc89dc-8eab-4d37-894b-02533b292213"
      },
      "source": [
        "# Mount the google drive in google colab\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWWOLwHlyxL3",
        "colab_type": "text"
      },
      "source": [
        "## **Importing Essential Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsOLN-xuFQFc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing essential libraries for computation\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import math\n",
        "import heapq\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MK8Wvq_Iy41k",
        "colab_type": "text"
      },
      "source": [
        "## **Loading and Preprocessing Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cargGhBshG0E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "76c8ce14-7be9-4c50-ca08-f2d39362440c"
      },
      "source": [
        "# Loading, and Checking the dataset\n",
        "\n",
        "\n",
        "count = 0\n",
        "with open('/content/drive/My Drive/colab_notes/datasets/australian_users_items.json') as f:\n",
        "  users = dict()\n",
        "  for line in f:\n",
        "    count += 1\n",
        "number_of_users = count\n",
        "print(number_of_users)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "88310\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AE_rO_0oblJ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parsing the json dataset into a dictionary containing user_id, items_count and items\n",
        "\n",
        "count = 0\n",
        "with open('/content/drive/My Drive/colab_notes/datasets/australian_users_items.json') as f:\n",
        "  users = dict()\n",
        "  for line in f:\n",
        "    \n",
        "    line = line.split(',')\n",
        "    #print(line)\n",
        "    #line = str(line).split(':')\n",
        "    \n",
        "    user = dict()\n",
        "    \n",
        "    #print(line[0])\n",
        "    user['user_id'] = line[0]\n",
        "    user['items_count'] = line[1]\n",
        "    user['items'] = line[5:]\n",
        "    users[count] = user\n",
        "    count+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZRYyMkkblEm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# converting the parsed json file into a pandas dataframe\n",
        "df = pd.DataFrame(list(users.items()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6j0d5dFl3DU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extracting the user_id and items and items_counts from the dataframe into independent columns\n",
        "user_id = list()\n",
        "items_count = list()\n",
        "items = list()\n",
        "for i in range(len(df)):\n",
        "  user_id.append(df[1][i]['user_id'])\n",
        "  items_count.append(df[1][i]['items_count'])\n",
        "  items.append(df[1][i]['items'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpUeRZLFnSsd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Extracting the specific values of user_id and items count\n",
        "for i in range(len(user_id)):\n",
        "  user_id[i] = user_id[i][11:].replace(\"'\", \"\")\n",
        "  items_count[i] = int(items_count[i][16:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VXjD5xOrHMD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# inserting user_id and items_count into the dataframe\n",
        "df['user_id'] = user_id\n",
        "df['items_count'] = items_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGkMt1WJrHF-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a98ac438-d6ca-4e9a-9f7f-2e64bb8651dd"
      },
      "source": [
        "# DataFrame first five elements\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>user_id</th>\n",
              "      <th>items_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>{'user_id': '{'user_id': '76561197970982479'',...</td>\n",
              "      <td>76561197970982479</td>\n",
              "      <td>277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>{'user_id': '{'user_id': 'js41637'', 'items_co...</td>\n",
              "      <td>js41637</td>\n",
              "      <td>888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>{'user_id': '{'user_id': 'evcentric'', 'items_...</td>\n",
              "      <td>evcentric</td>\n",
              "      <td>137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>{'user_id': '{'user_id': 'Riot-Punch'', 'items...</td>\n",
              "      <td>Riot-Punch</td>\n",
              "      <td>328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>{'user_id': '{'user_id': 'doctr'', 'items_coun...</td>\n",
              "      <td>doctr</td>\n",
              "      <td>541</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0  ... items_count\n",
              "0  0  ...         277\n",
              "1  1  ...         888\n",
              "2  2  ...         137\n",
              "3  3  ...         328\n",
              "4  4  ...         541\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lF4REX3R8nJI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "e88cae1e-3acc-4be4-d460-2a74d3448563"
      },
      "source": [
        "# Distribution of items_counts\n",
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>items_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>88310.000000</td>\n",
              "      <td>88310.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>44154.500000</td>\n",
              "      <td>58.353629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>25493.045473</td>\n",
              "      <td>122.312095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>22077.250000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>44154.500000</td>\n",
              "      <td>26.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>66231.750000</td>\n",
              "      <td>73.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>88309.000000</td>\n",
              "      <td>7762.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  0   items_count\n",
              "count  88310.000000  88310.000000\n",
              "mean   44154.500000     58.353629\n",
              "std    25493.045473    122.312095\n",
              "min        0.000000      0.000000\n",
              "25%    22077.250000      3.000000\n",
              "50%    44154.500000     26.000000\n",
              "75%    66231.750000     73.000000\n",
              "max    88309.000000   7762.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Md_wIX4a8nFm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Since this is very sparse matrix, I will be focusing on users with more than 75th percentile items_counts\n",
        "df = df[df['items_count']>188]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iml8hKTg9eDi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "a43038f0-ea55-4a17-da0f-4e2e592931c8"
      },
      "source": [
        "# Distribution of the items_count in the new dataframe\n",
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>items_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5451.000000</td>\n",
              "      <td>5451.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>25270.399376</td>\n",
              "      <td>354.778206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>17244.453144</td>\n",
              "      <td>344.401795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>189.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>11126.000000</td>\n",
              "      <td>220.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>22532.000000</td>\n",
              "      <td>267.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>37643.000000</td>\n",
              "      <td>366.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>88303.000000</td>\n",
              "      <td>7762.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  0  items_count\n",
              "count   5451.000000  5451.000000\n",
              "mean   25270.399376   354.778206\n",
              "std    17244.453144   344.401795\n",
              "min        0.000000   189.000000\n",
              "25%    11126.000000   220.000000\n",
              "50%    22532.000000   267.000000\n",
              "75%    37643.000000   366.000000\n",
              "max    88303.000000  7762.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06f6fN8xGAEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# adding a column to the dataframe for index\n",
        "idx = list(range(len(df)))\n",
        "df['idx'] = idx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFLqsMfp-PPv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "806897d1-be39-453d-990c-3991d15d95a1"
      },
      "source": [
        "# Droppping the first column\n",
        "df.drop(0, axis=1, inplace=True)\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>user_id</th>\n",
              "      <th>items_count</th>\n",
              "      <th>idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'user_id': '{'user_id': '76561197970982479'',...</td>\n",
              "      <td>76561197970982479</td>\n",
              "      <td>277</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'user_id': '{'user_id': 'js41637'', 'items_co...</td>\n",
              "      <td>js41637</td>\n",
              "      <td>888</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'user_id': '{'user_id': 'Riot-Punch'', 'items...</td>\n",
              "      <td>Riot-Punch</td>\n",
              "      <td>328</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'user_id': '{'user_id': 'doctr'', 'items_coun...</td>\n",
              "      <td>doctr</td>\n",
              "      <td>541</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>{'user_id': '{'user_id': 'MinxIsBetterThanPota...</td>\n",
              "      <td>MinxIsBetterThanPotatoes</td>\n",
              "      <td>371</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>{'user_id': '{'user_id': 'NitemarePK'', 'items...</td>\n",
              "      <td>NitemarePK</td>\n",
              "      <td>304</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>{'user_id': '{'user_id': 'themanwich'', 'items...</td>\n",
              "      <td>themanwich</td>\n",
              "      <td>258</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>{'user_id': '{'user_id': 'maplemage'', 'items_...</td>\n",
              "      <td>maplemage</td>\n",
              "      <td>629</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>{'user_id': '{'user_id': 'cadmusthreepointoh''...</td>\n",
              "      <td>cadmusthreepointoh</td>\n",
              "      <td>253</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>{'user_id': '{'user_id': 'thequeenpanda'', 'it...</td>\n",
              "      <td>thequeenpanda</td>\n",
              "      <td>524</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    1  ... idx\n",
              "0   {'user_id': '{'user_id': '76561197970982479'',...  ...   0\n",
              "1   {'user_id': '{'user_id': 'js41637'', 'items_co...  ...   1\n",
              "3   {'user_id': '{'user_id': 'Riot-Punch'', 'items...  ...   2\n",
              "4   {'user_id': '{'user_id': 'doctr'', 'items_coun...  ...   3\n",
              "5   {'user_id': '{'user_id': 'MinxIsBetterThanPota...  ...   4\n",
              "6   {'user_id': '{'user_id': 'NitemarePK'', 'items...  ...   5\n",
              "7   {'user_id': '{'user_id': 'themanwich'', 'items...  ...   6\n",
              "8   {'user_id': '{'user_id': 'maplemage'', 'items_...  ...   7\n",
              "13  {'user_id': '{'user_id': 'cadmusthreepointoh''...  ...   8\n",
              "21  {'user_id': '{'user_id': 'thequeenpanda'', 'it...  ...   9\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDBiVZHsH2S7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setting index for consistent indexing\n",
        "df.set_index('idx', inplace=True, drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c21NWk5CCg4y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "73ffa166-10a8-4821-ac63-965617184c80"
      },
      "source": [
        "# Shape of the dataframe\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5451, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMi4ZJcArG3C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A loop for extracting the steam video games played by every user\n",
        "\n",
        "users = list() # A list to hold list of users' played steam video games\n",
        "\n",
        "for i in range(len(df['user_id'])):  ## Looping over every user\n",
        "  user = list()\n",
        "  j = 0\n",
        "  while j < df['items_count'][i]: ## Looping over the items, extracting the item names and appending to list of respective user\n",
        "    if df[1][i]['items'][j][15:].strip() not in user and df[1][i]['items'][j][15:].strip() != None:\n",
        "      user.append(df[1][i]['items'][j][15:].strip())\n",
        "    j+=4\n",
        "  users.append(user) # Appending every user's played steam video games to users list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYHQfkdQi-su",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initializing a list to hold unique steam video games played by the users\n",
        "video_list = list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRUCWj_Ai-pN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A loop to extract unique steam video games\n",
        "\n",
        "for i in range(len(users)):  # looping over every user \n",
        "\n",
        "  len_user = len(users[i])\n",
        "\n",
        "  for j in range(len_user): # looping over every steam video game played by the user\n",
        "\n",
        "    if users[i][j] not in video_list:\n",
        "      video_list.append(users[i][j])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXq1K_LXi-WQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Formulating a sparse matrix  - every against every user against\n",
        "\n",
        "vid_vec = list()\n",
        "for vid in video_list:\n",
        "\n",
        "  vid_values = [0]* len(users)\n",
        "\n",
        "  for j in range(len(users)):\n",
        "\n",
        "    if vid in users[j]:\n",
        "      vid_values[j] = 1\n",
        "\n",
        "  vid_vec.append(vid_values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCnB5EiWi-Ra",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a dataset out of the sparse matrix\n",
        "\n",
        "vid_df = pd.DataFrame(vid_vec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRWooIZeJsGK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "f183b757-1b5b-47c0-8fba-602706948515"
      },
      "source": [
        "#movies_df.columns = movie_list\n",
        "\n",
        "#columns: users\n",
        "#rows : steam video games played by the users\n",
        "\n",
        "vid_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>5411</th>\n",
              "      <th>5412</th>\n",
              "      <th>5413</th>\n",
              "      <th>5414</th>\n",
              "      <th>5415</th>\n",
              "      <th>5416</th>\n",
              "      <th>5417</th>\n",
              "      <th>5418</th>\n",
              "      <th>5419</th>\n",
              "      <th>5420</th>\n",
              "      <th>5421</th>\n",
              "      <th>5422</th>\n",
              "      <th>5423</th>\n",
              "      <th>5424</th>\n",
              "      <th>5425</th>\n",
              "      <th>5426</th>\n",
              "      <th>5427</th>\n",
              "      <th>5428</th>\n",
              "      <th>5429</th>\n",
              "      <th>5430</th>\n",
              "      <th>5431</th>\n",
              "      <th>5432</th>\n",
              "      <th>5433</th>\n",
              "      <th>5434</th>\n",
              "      <th>5435</th>\n",
              "      <th>5436</th>\n",
              "      <th>5437</th>\n",
              "      <th>5438</th>\n",
              "      <th>5439</th>\n",
              "      <th>5440</th>\n",
              "      <th>5441</th>\n",
              "      <th>5442</th>\n",
              "      <th>5443</th>\n",
              "      <th>5444</th>\n",
              "      <th>5445</th>\n",
              "      <th>5446</th>\n",
              "      <th>5447</th>\n",
              "      <th>5448</th>\n",
              "      <th>5449</th>\n",
              "      <th>5450</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 5451 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   0     1     2     3     4     5     ...  5445  5446  5447  5448  5449  5450\n",
              "0     1     1     1     1     0     0  ...     0     1     0     0     0     0\n",
              "1     1     1     1     1     0     1  ...     0     0     0     0     0     0\n",
              "2     1     1     1     1     0     0  ...     0     0     0     0     0     0\n",
              "3     1     1     1     1     0     0  ...     0     0     0     0     0     0\n",
              "4     1     1     1     1     1     1  ...     0     0     0     0     0     0\n",
              "\n",
              "[5 rows x 5451 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IRzgCrqgBvW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "429bfbda-e31e-412c-e008-29d542f69742"
      },
      "source": [
        "# Shape of the dataset\n",
        "vid_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7851, 5451)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiY5q0Djc-u6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a list of tuples  - (user_id, product_id)\n",
        "\n",
        "count = 0\n",
        "idx_lst = list()\n",
        "for i in range(vid_df.shape[1]):\n",
        "\n",
        "  \n",
        "  for j in range(vid_df.shape[0]):\n",
        "    \n",
        "    if vid_df[i][j] == 1:\n",
        "      idx_lst.append((i,j))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATbEe2i3c_F1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3a44fc56-cf1a-498f-f53b-f3063eda8d57"
      },
      "source": [
        "# Number of the user - video combination\n",
        "len(idx_lst)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "409325"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EASbJnkc_XZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a dataframe from the list of tuples\n",
        "# A dataframe focused on the interaction between users (reviewers) and steam videos()\n",
        "\n",
        "df_review = pd.DataFrame(idx_lst, columns=['reviewerID', 'productID'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bej7IHYkc-3S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d8f08f8f-ad6e-4279-f0ce-d040ff3a7610"
      },
      "source": [
        "# First five elements of the dataset\n",
        "df_review.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviewerID</th>\n",
              "      <th>productID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   reviewerID  productID\n",
              "0           0          0\n",
              "1           0          1\n",
              "2           0          2\n",
              "3           0          3\n",
              "4           0          4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7Q5a07Zzhyr",
        "colab_type": "text"
      },
      "source": [
        "#### Helping Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wL12zEI1sXyq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mask_first(x):\n",
        "    \"\"\"\n",
        "    Return a list of 0 for the first item and 1 for all others\n",
        "    \"\"\"\n",
        "    result = np.ones_like(x)\n",
        "\n",
        "    result[0] = 0\n",
        "    \n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrrqfJbinR-1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_test_split(df):\n",
        "    \"\"\"\n",
        "    Splits our original data into one test and one\n",
        "    training set. \n",
        "    The test set is made up of one item for each user. This is\n",
        "    our holdout item used to compute Top@K later.\n",
        "    The training set is the same as our original data but\n",
        "    without any of the holdout items.\n",
        "    Args:\n",
        "        df (dataframe): Our original data\n",
        "    Returns:\n",
        "        df_train (dataframe): All of our data except holdout items\n",
        "        df_test (dataframe): Only our holdout items.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create two copies of our dataframe that we can modify\n",
        "    df_test = df.copy(deep=True)\n",
        "    df_train = df.copy(deep=True)\n",
        "\n",
        "    # Group by user_id and select only the first item for\n",
        "    # each user (our holdout).\n",
        "    df_test = df_test.groupby(['reviewerID']).first()\n",
        "    df_test['reviewerID'] = df_test.index\n",
        "    df_test = df_test[['reviewerID', 'productID']]\n",
        "    df_test.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    # Remove the same items as we for our test set in our training set.\n",
        "    mask = df.groupby(['reviewerID'])['reviewerID'].transform(mask_first).astype(bool)\n",
        "    df_train = df.loc[mask]\n",
        "\n",
        "    return df_train, df_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1-TgY-2ahhH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create training and test sets.\n",
        "df_train, df_test = train_test_split(df_review)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPddLjBYahaR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # Create lists of all unique reviewers and products\n",
        "reviewers = list(np.sort(df_review.reviewerID.unique()))\n",
        "products = list(np.sort(df_review.productID.unique()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9jPHNHCahYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the rows, columns and values for our matrix.\n",
        "rows = df_train.reviewerID.astype(int)\n",
        "cols = df_train.productID.astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLlMgupyUW0u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # Get all reviewer ids and product ids.\n",
        "uids = np.array(rows.tolist())\n",
        "iids = np.array(cols.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7i1K1eBGZJm1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Naming conventions in the notebook\n",
        "\n",
        "# Items = products\n",
        "\n",
        "# Users = reviewers\n",
        "\n",
        "items = products\n",
        "users = reviewers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYByetIxnGPg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_negatives(uids, iids, items, df_test):\n",
        "    \"\"\"Returns a pandas dataframe of 100 negative interactions\n",
        "    based for each user in df_test.\n",
        "    Args:\n",
        "        uids (np.array): Numpy array of all user ids.\n",
        "        iids (np.array): Numpy array of all item ids.\n",
        "        items (list): List of all unique items.\n",
        "        df_test (dataframe): Our test set.\n",
        "    Returns:\n",
        "        df_neg (dataframe): dataframe with 100 negative items \n",
        "            for each (u, i) pair in df_test.\n",
        "    \"\"\"\n",
        "\n",
        "    negativeList = []\n",
        "    test_u = df_test['reviewerID'].values.tolist()\n",
        "    test_i = df_test['productID'].values.tolist()\n",
        "\n",
        "    test_ratings = list(zip(test_u, test_i))\n",
        "    zipped = set(zip(uids, iids))\n",
        "\n",
        "    for (u, i) in test_ratings:\n",
        "        negatives = []\n",
        "        negatives.append((u, i))\n",
        "        for t in range(100):\n",
        "            j = np.random.randint(len(items)) # Get random item id.\n",
        "            while (u, j) in zipped: # Check if there is an interaction\n",
        "                j = np.random.randint(len(items)) # If yes, generate a new item id\n",
        "            negatives.append(j) # Once a negative interaction is found we add it.\n",
        "        negativeList.append(negatives)\n",
        "\n",
        "    df_neg = pd.DataFrame(negativeList)\n",
        "\n",
        "    return df_neg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jItXHabnGLC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sample 100 negative interactions for each user in our test data\n",
        "df_neg = get_negatives(uids, iids, products, df_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dFKyRiEnGAS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from random import shuffle\n",
        "\n",
        "def get_train_instances():\n",
        "     \"\"\"Samples a number of negative user-item interactions for each\n",
        "     user-item pair in our testing data.\n",
        "     Returns:\n",
        "         user_input (list): A list of all users for each item\n",
        "         item_input (list): A list of all items for every user,\n",
        "             both positive and negative interactions.\n",
        "         labels (list): A list of all labels. 0 or 1.\n",
        "     \"\"\"\n",
        "\n",
        "     user_input, item_input, labels = [],[],[]\n",
        "     zipped = set(zip(uids, iids))\n",
        "\n",
        "     for (u, i) in zip(uids,iids):\n",
        "         # Add our positive interaction\n",
        "         user_input.append(u)\n",
        "         item_input.append(i)\n",
        "         labels.append(1)\n",
        "\n",
        "         # Sample a number of random negative interactions\n",
        "         for t in range(num_neg):\n",
        "             j = np.random.randint(len(products))\n",
        "             while (u, j) in zipped:\n",
        "                 j = np.random.randint(len(products))\n",
        "             user_input.append(u)\n",
        "             item_input.append(j)\n",
        "             labels.append(0)\n",
        "\n",
        "     return user_input, item_input, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hc5likoyVTmp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_mini_batches(shuffled_U, shuffled_I, shuffled_L, mini_batch_size=256):\n",
        "    \"\"\"Returns a list of shuffeled mini batched of a given size.\n",
        "    Args:\n",
        "        U (list): All users for every interaction \n",
        "        I (list): All items for every interaction\n",
        "        L (list): All labels for every interaction.\n",
        "    \n",
        "    Returns:\n",
        "        mini_batches (list): A list of minibatches containing sets\n",
        "            of batch users, batch items and batch labels \n",
        "            [(u, i, l), (u, i, l) ...]\n",
        "    \"\"\"\n",
        "\n",
        "    mini_batches = []\n",
        "\n",
        "    #shuffled_U, shuffled_I, shuffled_L = shuffle(U, I, L)\n",
        "\n",
        "    U = (shuffled_U)\n",
        "\n",
        "    num_complete_batches = int(math.floor(len(U)/mini_batch_size))\n",
        "    for k in range(0, num_complete_batches):\n",
        "        mini_batch_U = shuffled_U[k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
        "        mini_batch_I = shuffled_I[k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
        "        mini_batch_L = shuffled_L[k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
        "\n",
        "        mini_batch = (mini_batch_U, mini_batch_I, mini_batch_L)\n",
        "        mini_batches.append(mini_batch)\n",
        "\n",
        "    if len(U) % mini_batch_size != 0:\n",
        "        mini_batch_U = shuffled_U[num_complete_batches * mini_batch_size: len(U)]\n",
        "        mini_batch_I = shuffled_I[num_complete_batches * mini_batch_size: len(U)]\n",
        "        mini_batch_L = shuffled_L[num_complete_batches * mini_batch_size: len(U)]\n",
        "\n",
        "        mini_batch = (mini_batch_U, mini_batch_I, mini_batch_L)\n",
        "        mini_batches.append(mini_batch)\n",
        "\n",
        "    return mini_batches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQM79sb5VTjF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_hits(k_ranked, holdout):\n",
        "    \"\"\"Return 1 if an item exists in a given list and 0 if not. \"\"\"\n",
        "\n",
        "    for item in k_ranked:\n",
        "        if item == holdout:\n",
        "            return 1\n",
        "    return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2SonJIUVTdf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def eval_rating(idx, test_ratings, test_negatives, K):\n",
        "    \"\"\"Generate ratings for the users in our test set and\n",
        "    check if our holdout item is among the top K highest scores.\n",
        "    Args:\n",
        "        idx (int): Current index\n",
        "        test_ratings (list): Our test set user-item pairs\n",
        "        test_negatives (list): 100 negative items for each\n",
        "            user in our test set.\n",
        "        K (int): number of top recommendations\n",
        "    Returns:\n",
        "        hr (list): A list of 1 if the holdout appeared in our\n",
        "            top K predicted items. 0 if not.\n",
        "    \"\"\"\n",
        "\n",
        "    map_item_score = {}\n",
        "\n",
        "    # Get the negative interactions our user.\n",
        "    items = test_negatives[idx]\n",
        "\n",
        "    # Get the user idx.\n",
        "    user_idx = test_ratings[idx][0]\n",
        "\n",
        "    # Get the item idx, i.e. our holdout item.\n",
        "    holdout = test_ratings[idx][1]\n",
        "\n",
        "    # Add the holdout to the end of the negative interactions list.\n",
        "    items.append(holdout)\n",
        "\n",
        "    # Prepare our user and item arrays for tensorflow.\n",
        "    predict_user = np.full(len(items), user_idx, dtype='int32').reshape(-1,1)\n",
        "    np_items = np.array(items).reshape(-1,1)\n",
        "\n",
        "    # Feed user and items into the TF graph .\n",
        "    predictions = session.run([output_layer], feed_dict={user: predict_user, item: np_items})\n",
        "\n",
        "    # Get the predicted scores as a list\n",
        "    predictions = predictions[0].flatten().tolist()\n",
        "\n",
        "    # Map predicted score to item id.\n",
        "    for i in range(len(items)):\n",
        "        current_item = items[i]\n",
        "        map_item_score[current_item] = predictions[i]\n",
        "\n",
        "    # Get the K highest ranked items as a list\n",
        "    k_ranked = heapq.nlargest(K, map_item_score, key=map_item_score.get)\n",
        "\n",
        "    # Get a list of hit or no hit.   \n",
        "    hits = get_hits(k_ranked, holdout)\n",
        "\n",
        "    return hits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONIsmMnUKCJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(df_neg, K=10):\n",
        "    \"\"\"Calculate the top@K hit ratio for our recommendations.\n",
        "    Args:\n",
        "        df_neg (dataframe): dataframe containing our holdout items\n",
        "            and 100 randomly sampled negative interactions for each\n",
        "            (user, item) holdout pair.\n",
        "        K (int): The 'K' number of ranked predictions we want\n",
        "            our holdout item to be present in. \n",
        "    Returns:\n",
        "        hits (list): list of \"hits\". 1 if the holdout was present in \n",
        "            the K highest ranked predictions. 0 if not. \n",
        "    \"\"\"\n",
        "\n",
        "    hits = []\n",
        "\n",
        "    test_u = df_test['reviewerID'].values.tolist()\n",
        "    test_i = df_test['productID'].values.tolist()\n",
        "\n",
        "    test_ratings = list(zip(test_u, test_i))\n",
        "\n",
        "    df_neg = df_neg.drop(df_neg.columns[0], axis=1)\n",
        "    test_negatives = df_neg.values.tolist()\n",
        "\n",
        "    for idx in range(len(test_ratings)):\n",
        "        # For each idx, call eval_one_rating\n",
        "        hitrate = eval_rating(idx, test_ratings, test_negatives, K)\n",
        "        hits.append(hitrate)\n",
        "\n",
        "    return hits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jijXH5dzuam",
        "colab_type": "text"
      },
      "source": [
        "## **Generalized Collaborative Filtering (GCF)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul3jn4umWDMg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#-------------\n",
        "# HYPERPARAMS\n",
        "#-------------\n",
        "\n",
        "num_neg = 4\n",
        "latent_features = 8\n",
        "epochs = 20\n",
        "batch_size = 256\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "\n",
        "#-------------------------\n",
        "# TENSORFLOW GRAPH\n",
        "#-------------------------\n",
        "\n",
        "graph = tf.Graph()\n",
        "\n",
        "with graph.as_default():\n",
        "\n",
        "    # Define input placeholders for user, item and label.\n",
        "    user = tf.compat.v1.placeholder(tf.int32, shape=(None, 1))\n",
        "    item = tf.compat.v1.placeholder(tf.int32, shape=(None, 1))\n",
        "    label = tf.compat.v1.placeholder(tf.int32, shape=(None, 1))\n",
        "\n",
        "    # User feature embedding\n",
        "    u_var = tf.Variable(tf.compat.v1.random_normal([len(users), latent_features],\n",
        "                                         stddev=0.05), name='user_embedding')\n",
        "    user_embedding = tf.nn.embedding_lookup(u_var, user)\n",
        "\n",
        "    # Item feature embedding\n",
        "    i_var = tf.Variable(tf.compat.v1.random_normal([len(items), latent_features],\n",
        "                                         stddev=0.05), name='item_embedding')\n",
        "    item_embedding = tf.nn.embedding_lookup(i_var, item)\n",
        "    \n",
        "    # Flatten our user and item embeddings.\n",
        "    user_embedding = tf.keras.layers.Flatten()(user_embedding)\n",
        "    item_embedding = tf.keras.layers.Flatten()(item_embedding)\n",
        "\n",
        "    # Multiplying our user and item latent space vectors together \n",
        "    prediction_matrix = tf.multiply(user_embedding, item_embedding)\n",
        "\n",
        "    # Our single neuron output layer\n",
        "    output_layer = tf.keras.layers.Dense(1, \n",
        "            kernel_initializer=\"lecun_uniform\",\n",
        "            name='output_layer')(prediction_matrix)\n",
        "\n",
        "    # Our loss function as a binary cross entropy. \n",
        "    loss = tf.compat.v1.losses.sigmoid_cross_entropy(label, output_layer)\n",
        "    \n",
        "    # Train using the Adam optimizer to minimize our loss.\n",
        "    opt = tf.compat.v1.train.AdamOptimizer(learning_rate = learning_rate)\n",
        "    step = opt.minimize(loss)\n",
        "\n",
        "    # Initialize all tensorflow variables.\n",
        "    init = tf.compat.v1.global_variables_initializer()\n",
        "\n",
        "session = tf.compat.v1.Session(config=None, graph=graph)\n",
        "session.run(init)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SirerySrWDQL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "b839fe99-d104-4d7a-e697-3e8c4b2ade40"
      },
      "source": [
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    # Get our training input.\n",
        "    user_input, item_input, labels = get_train_instances()\n",
        "\n",
        "    # Generate a list of minibatches.\n",
        "    minibatches = random_mini_batches(user_input, item_input, labels)\n",
        "\n",
        "    # This has noting to do with tensorflow but gives\n",
        "    # us a nice progress bar for the training\n",
        "    progress = tqdm(total=len(minibatches))\n",
        "\n",
        "    # Loop over each batch and feed our users, items and labels\n",
        "    # into our graph. \n",
        "    for minibatch in minibatches:\n",
        "        feed_dict = {user: np.array(minibatch[0]).reshape(-1,1),\n",
        "                    item: np.array(minibatch[1]).reshape(-1,1),\n",
        "                    label: np.array(minibatch[2]).reshape(-1,1)}\n",
        "   \n",
        "        # Execute the graph.\n",
        "        _, l = session.run([step, loss], feed_dict)\n",
        "\n",
        "        # Update the progress\n",
        "        progress.update(1)\n",
        "        progress.set_description('Epoch: %d - Loss: %.3f' % (epoch+1, l))\n",
        "\n",
        "    progress.close()\n",
        "\n",
        "\n",
        "# Calculate top@K    \n",
        "hits = evaluate(df_neg)\n",
        "print(np.array(hits).mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 - Loss: 0.488: 100%|██████████| 7889/7889 [00:35<00:00, 223.76it/s]\n",
            "Epoch: 2 - Loss: 0.579: 100%|██████████| 7889/7889 [00:35<00:00, 223.10it/s]\n",
            "Epoch: 3 - Loss: 0.467: 100%|██████████| 7889/7889 [00:35<00:00, 224.07it/s]\n",
            "Epoch: 4 - Loss: 0.454: 100%|██████████| 7889/7889 [00:35<00:00, 223.42it/s]\n",
            "Epoch: 5 - Loss: 0.499: 100%|██████████| 7889/7889 [00:35<00:00, 222.40it/s]\n",
            "Epoch: 6 - Loss: 0.420: 100%|██████████| 7889/7889 [00:34<00:00, 225.87it/s]\n",
            "Epoch: 7 - Loss: 0.362: 100%|██████████| 7889/7889 [00:34<00:00, 227.38it/s]\n",
            "Epoch: 8 - Loss: 0.473: 100%|██████████| 7889/7889 [00:35<00:00, 220.22it/s]\n",
            "Epoch: 9 - Loss: 0.280: 100%|██████████| 7889/7889 [00:35<00:00, 221.90it/s]\n",
            "Epoch: 10 - Loss: 0.406: 100%|██████████| 7889/7889 [00:35<00:00, 224.93it/s]\n",
            "Epoch: 11 - Loss: 0.201: 100%|██████████| 7889/7889 [00:35<00:00, 222.48it/s]\n",
            "Epoch: 12 - Loss: 0.506: 100%|██████████| 7889/7889 [00:34<00:00, 231.06it/s]\n",
            "Epoch: 13 - Loss: 0.196: 100%|██████████| 7889/7889 [00:35<00:00, 221.47it/s]\n",
            "Epoch: 14 - Loss: 0.343: 100%|██████████| 7889/7889 [00:34<00:00, 225.77it/s]\n",
            "Epoch: 15 - Loss: 0.180: 100%|██████████| 7889/7889 [00:34<00:00, 228.02it/s]\n",
            "Epoch: 16 - Loss: 0.361: 100%|██████████| 7889/7889 [00:34<00:00, 226.02it/s]\n",
            "Epoch: 17 - Loss: 0.130: 100%|██████████| 7889/7889 [00:35<00:00, 224.07it/s]\n",
            "Epoch: 18 - Loss: 0.238: 100%|██████████| 7889/7889 [00:34<00:00, 226.25it/s]\n",
            "Epoch: 19 - Loss: 0.411: 100%|██████████| 7889/7889 [00:34<00:00, 228.99it/s]\n",
            "Epoch: 20 - Loss: 0.324: 100%|██████████| 7889/7889 [00:34<00:00, 225.62it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.7475692533480095\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoS5fFq7aOfe",
        "colab_type": "text"
      },
      "source": [
        "# **Multi-Layer Perceptron (MLP)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxPzLbx5WECh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#-------------\n",
        "# HYPERPARAMS\n",
        "#-------------\n",
        "\n",
        "num_neg = 4\n",
        "epochs = 20\n",
        "batch_size = 256\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "#-------------------------\n",
        "# TENSORFLOW GRAPH\n",
        "#-------------------------\n",
        "\n",
        "# Set up our Tensorflow graph\n",
        "graph = tf.Graph()\n",
        "\n",
        "with graph.as_default():\n",
        "\n",
        "    # Define input placeholders for user, item and label.\n",
        "    user = tf.compat.v1.placeholder(tf.int32, shape=(None, 1))\n",
        "    item = tf.compat.v1.placeholder(tf.int32, shape=(None, 1))\n",
        "    label = tf.compat.v1.placeholder(tf.int32, shape=(None, 1))\n",
        "\n",
        "    # User feature embedding\n",
        "    u_var = tf.Variable(tf.compat.v1.random_normal([len(users), 32], stddev=0.05), name='user_embedding')\n",
        "    user_embedding = tf.nn.embedding_lookup(u_var, user)\n",
        "\n",
        "    # Item feature embedding\n",
        "    i_var = tf.Variable(tf.compat.v1.random_normal([len(items), 32], stddev=0.05), name='item_embedding')\n",
        "    item_embedding = tf.nn.embedding_lookup(i_var, item)\n",
        "\n",
        "    # Flatten our user and item embeddings.\n",
        "    user_embedding = tf.keras.layers.Flatten()(user_embedding)\n",
        "    item_embedding = tf.keras.layers.Flatten()(item_embedding)\n",
        "\n",
        "    # Concatenate our two embedding vectors together\n",
        "    concatenated = tf.keras.layers.concatenate([user_embedding, item_embedding])\n",
        "\n",
        "    # Add a first dropout layer.\n",
        "    dropout = tf.keras.layers.Dropout(0.2)(concatenated)\n",
        "\n",
        "    # Below we add our four hidden layers along with batch\n",
        "    # normalization and dropouts. We use relu as the activation function.\n",
        "    layer_1 = tf.keras.layers.Dense(64, activation='relu', name='layer1')(dropout)\n",
        "    batch_norm1 = tf.keras.layers.BatchNormalization(name='batch_norm1')(layer_1)\n",
        "    dropout1 = tf.keras.layers.Dropout(0.2, name='dropout1')(batch_norm1)\n",
        "\n",
        "    layer_2 = tf.keras.layers.Dense(32, activation='relu', name='layer2')(layer_1)\n",
        "    batch_norm2 = tf.keras.layers.BatchNormalization(name='batch_norm1')(layer_2)\n",
        "    dropout2 = tf.keras.layers.Dropout(0.2, name='dropout1')(batch_norm2)\n",
        "\n",
        "    layer_3 = tf.keras.layers.Dense(16, activation='relu', name='layer3')(layer_2)\n",
        "    layer_4 = tf.keras.layers.Dense(8, activation='relu', name='layer4')(layer_3)\n",
        "\n",
        "    # Our final single neuron output layer.\n",
        "    output_layer = tf.keras.layers.Dense(1,\n",
        "            kernel_initializer=\"lecun_uniform\",\n",
        "            name='output_layer')(layer_4)\n",
        "\n",
        "    # Define our loss function as binary cross entropy.\n",
        "    labels = tf.cast(label, tf.float32)\n",
        "    logits = output_layer\n",
        "    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "                labels=labels,\n",
        "                logits=logits))\n",
        "\n",
        "    # Train using the Adam optimizer to minimize our loss.\n",
        "    opt = tf.compat.v1.train.AdamOptimizer(learning_rate = learning_rate)\n",
        "    step = opt.minimize(loss)\n",
        "\n",
        "    # Initialize all tensorflow variables.\n",
        "    init = tf.compat.v1.global_variables_initializer()\n",
        "\n",
        "session = tf.compat.v1.Session(config=None, graph=graph)\n",
        "session.run(init)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "An_WdgjXWD6h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "e1f99361-8c7a-406e-acbc-99d89fccfdd4"
      },
      "source": [
        "for epoch in range(epochs):\n",
        "\n",
        "    # Get our training input.\n",
        "    user_input, item_input, labels = get_train_instances()\n",
        "\n",
        "    # Generate a list of minibatches.\n",
        "    minibatches = random_mini_batches(user_input, item_input, labels)\n",
        "\n",
        "    # This has noting to do with tensorflow but gives\n",
        "    # us a nice progress bar for the training\n",
        "    progress = tqdm(total=len(minibatches))\n",
        "\n",
        "    # Loop over each batch and feed our users, items and labels\n",
        "    # into our graph. \n",
        "    for minibatch in minibatches:\n",
        "        feed_dict = {user: np.array(minibatch[0]).reshape(-1,1),\n",
        "                    item: np.array(minibatch[1]).reshape(-1,1),\n",
        "                    label: np.array(minibatch[2]).reshape(-1,1)}\n",
        "   \n",
        "        # Execute the graph.\n",
        "        _, l = session.run([step, loss], feed_dict)\n",
        "\n",
        "        # Update the progress\n",
        "        progress.update(1)\n",
        "        progress.set_description('Epoch: %d - Loss: %.3f' % (epoch+1, l))\n",
        "\n",
        "    progress.close()\n",
        "\n",
        "\n",
        "# Calculate top@K    \n",
        "hits = evaluate(df_neg)\n",
        "print(np.array(hits).mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 - Loss: 0.565: 100%|██████████| 7889/7889 [01:24<00:00, 93.17it/s]\n",
            "Epoch: 2 - Loss: 0.582: 100%|██████████| 7889/7889 [01:25<00:00, 92.42it/s]\n",
            "Epoch: 3 - Loss: 0.612: 100%|██████████| 7889/7889 [01:23<00:00, 94.27it/s]\n",
            "Epoch: 4 - Loss: 0.328: 100%|██████████| 7889/7889 [01:24<00:00, 93.51it/s]\n",
            "Epoch: 5 - Loss: 0.359: 100%|██████████| 7889/7889 [01:25<00:00, 92.45it/s]\n",
            "Epoch: 6 - Loss: 0.318: 100%|██████████| 7889/7889 [01:22<00:00, 95.61it/s]\n",
            "Epoch: 7 - Loss: 0.452: 100%|██████████| 7889/7889 [01:23<00:00, 94.31it/s]\n",
            "Epoch: 8 - Loss: 0.281: 100%|██████████| 7889/7889 [01:23<00:00, 94.41it/s]\n",
            "Epoch: 9 - Loss: 0.154: 100%|██████████| 7889/7889 [01:22<00:00, 95.09it/s]\n",
            "Epoch: 10 - Loss: 0.125: 100%|██████████| 7889/7889 [01:22<00:00, 95.31it/s]\n",
            "Epoch: 11 - Loss: 0.087: 100%|██████████| 7889/7889 [01:23<00:00, 94.21it/s]\n",
            "Epoch: 12 - Loss: 0.397: 100%|██████████| 7889/7889 [01:25<00:00, 92.63it/s]\n",
            "Epoch: 13 - Loss: 0.071: 100%|██████████| 7889/7889 [01:23<00:00, 94.86it/s]\n",
            "Epoch: 14 - Loss: 0.104: 100%|██████████| 7889/7889 [01:25<00:00, 92.06it/s]\n",
            "Epoch: 15 - Loss: 0.397: 100%|██████████| 7889/7889 [01:23<00:00, 94.59it/s]\n",
            "Epoch: 16 - Loss: 0.123: 100%|██████████| 7889/7889 [01:23<00:00, 94.87it/s]\n",
            "Epoch: 17 - Loss: 0.058: 100%|██████████| 7889/7889 [01:23<00:00, 94.04it/s]\n",
            "Epoch: 18 - Loss: 0.159: 100%|██████████| 7889/7889 [01:23<00:00, 94.06it/s]\n",
            "Epoch: 19 - Loss: 0.015: 100%|██████████| 7889/7889 [01:23<00:00, 94.02it/s]\n",
            "Epoch: 20 - Loss: 0.027: 100%|██████████| 7889/7889 [01:22<00:00, 95.63it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.7387635296275913\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awn3dtLDbfyX",
        "colab_type": "text"
      },
      "source": [
        "# **Combined (Generalized Collaborative Filatering and Multi-Layer Perceptron)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rrQSdGjWDvu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#-------------\n",
        "# HYPERPARAMS\n",
        "#-------------\n",
        "\n",
        "num_neg = 6\n",
        "latent_features = 8\n",
        "epochs = 20\n",
        "batch_size = 256\n",
        "learning_rate = 0.01\n",
        "\n",
        "\n",
        "# Load and prepare our data.\n",
        "#uids, iids, df_train, df_test, df_neg, users, items, item_lookup = load_dataset()\n",
        "\n",
        "\n",
        "\n",
        "#-------------------------\n",
        "# TENSORFLOW GRAPH\n",
        "#-------------------------\n",
        "\n",
        "graph = tf.Graph()\n",
        "\n",
        "with graph.as_default():\n",
        "\n",
        "    # Define input placeholders for user, item and label.\n",
        "    user = tf.compat.v1.placeholder(tf.int32, shape=(None, 1))\n",
        "    item = tf.compat.v1.placeholder(tf.int32, shape=(None, 1))\n",
        "    label = tf.compat.v1.placeholder(tf.int32, shape=(None, 1))\n",
        "\n",
        "    # User embedding for MLP\n",
        "    mlp_u_var = tf.Variable(tf.compat.v1.random_normal([len(users), 32], stddev=0.05),\n",
        "            name='mlp_user_embedding')\n",
        "    mlp_user_embedding = tf.nn.embedding_lookup(mlp_u_var, user)\n",
        "\n",
        "    # Item embedding for MLP\n",
        "    mlp_i_var = tf.Variable(tf.compat.v1.random_normal([len(items), 32], stddev=0.05),\n",
        "            name='mlp_item_embedding')\n",
        "    mlp_item_embedding = tf.nn.embedding_lookup(mlp_i_var, item)\n",
        "\n",
        "    # User embedding for GMF\n",
        "    gmf_u_var = tf.Variable(tf.compat.v1.random_normal([len(users), latent_features],\n",
        "        stddev=0.05), name='gmf_user_embedding')\n",
        "    gmf_user_embedding = tf.nn.embedding_lookup(gmf_u_var, user)\n",
        "\n",
        "    # Item embedding for GMF\n",
        "    gmf_i_var = tf.Variable(tf.compat.v1.random_normal([len(items), latent_features],\n",
        "        stddev=0.05), name='gmf_item_embedding')\n",
        "    gmf_item_embedding = tf.nn.embedding_lookup(gmf_i_var, item)\n",
        "\n",
        "    # Our GMF layers\n",
        "    gmf_user_embed = tf.keras.layers.Flatten()(gmf_user_embedding)\n",
        "    gmf_item_embed = tf.keras.layers.Flatten()(gmf_item_embedding)\n",
        "    gmf_matrix = tf.multiply(gmf_user_embed, gmf_item_embed)\n",
        "\n",
        "    # Our MLP layers\n",
        "    mlp_user_embed = tf.keras.layers.Flatten()(mlp_user_embedding)\n",
        "    mlp_item_embed = tf.keras.layers.Flatten()(mlp_item_embedding)\n",
        "    mlp_concat = tf.keras.layers.concatenate([mlp_user_embed, mlp_item_embed])\n",
        "\n",
        "    mlp_dropout = tf.keras.layers.Dropout(0.2)(mlp_concat)\n",
        "\n",
        "    mlp_layer_1 = tf.keras.layers.Dense(64, activation='relu', name='layer1')(mlp_dropout)\n",
        "    mlp_batch_norm1 = tf.keras.layers.BatchNormalization(name='batch_norm1')(mlp_layer_1)\n",
        "    mlp_dropout1 = tf.keras.layers.Dropout(0.2, name='dropout1')(mlp_batch_norm1)\n",
        "\n",
        "    mlp_layer_2 = tf.keras.layers.Dense(32, activation='relu', name='layer2')(mlp_dropout1)\n",
        "    mlp_batch_norm2 = tf.keras.layers.BatchNormalization(name='batch_norm1')(mlp_layer_2)\n",
        "    mlp_dropout2 = tf.keras.layers.Dropout(0.2, name='dropout1')(mlp_batch_norm2)\n",
        "\n",
        "    mlp_layer_3 = tf.keras.layers.Dense(16, activation='relu', name='layer3')(mlp_dropout2)\n",
        "    mlp_layer_4 = tf.keras.layers.Dense(8, activation='relu', name='layer4')(mlp_layer_3)\n",
        "\n",
        "    # We merge the two networks together\n",
        "    merged_vector = tf.keras.layers.concatenate([gmf_matrix, mlp_layer_4])\n",
        "\n",
        "    # Our final single neuron output layer. \n",
        "    output_layer = tf.keras.layers.Dense(1,\n",
        "            kernel_initializer=\"lecun_uniform\",\n",
        "            name='output_layer')(merged_vector)\n",
        "\n",
        "    # Our loss function as a binary cross entropy. \n",
        "    loss = tf.compat.v1.losses.sigmoid_cross_entropy(label, output_layer)\n",
        "\n",
        "    # Train using the Adam optimizer to minimize our loss.\n",
        "    opt = tf.compat.v1.train.AdamOptimizer(learning_rate = learning_rate)\n",
        "    step = opt.minimize(loss)\n",
        "\n",
        "    # Initialize all tensorflow variables.\n",
        "    init = tf.compat.v1.global_variables_initializer()\n",
        "\n",
        "\n",
        "session = tf.compat.v1.Session(config=None, graph=graph)\n",
        "session.run(init)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkfHTVVGbiXC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "c7ab568b-f75e-446f-cb6e-10eda0b78af1"
      },
      "source": [
        "for epoch in range(epochs):\n",
        "\n",
        "    # Get our training input.\n",
        "    user_input, item_input, labels = get_train_instances()\n",
        "\n",
        "    # Generate a list of minibatches.\n",
        "    minibatches = random_mini_batches(user_input, item_input, labels)\n",
        "\n",
        "    # This has noting to do with tensorflow but gives\n",
        "    # us a nice progress bar for the training\n",
        "    progress = tqdm(total=len(minibatches))\n",
        "\n",
        "    # Loop over each batch and feed our users, items and labels\n",
        "    # into our graph. \n",
        "    for minibatch in minibatches:\n",
        "        feed_dict = {user: np.array(minibatch[0]).reshape(-1,1),\n",
        "                    item: np.array(minibatch[1]).reshape(-1,1),\n",
        "                    label: np.array(minibatch[2]).reshape(-1,1)}\n",
        "   \n",
        "        # Execute the graph.\n",
        "        _, l = session.run([step, loss], feed_dict)\n",
        "\n",
        "        # Update the progress\n",
        "        progress.update(1)\n",
        "        progress.set_description('Epoch: %d - Loss: %.3f' % (epoch+1, l))\n",
        "\n",
        "    progress.close()\n",
        "\n",
        "\n",
        "# Calculate top@K    \n",
        "hits = evaluate(df_neg)\n",
        "print(np.array(hits).mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 - Loss: 0.356: 100%|██████████| 11044/11044 [02:11<00:00, 84.18it/s]\n",
            "Epoch: 2 - Loss: 0.455: 100%|██████████| 11044/11044 [02:08<00:00, 86.14it/s]\n",
            "Epoch: 3 - Loss: 0.440: 100%|██████████| 11044/11044 [02:06<00:00, 87.01it/s]\n",
            "Epoch: 4 - Loss: 0.328: 100%|██████████| 11044/11044 [02:07<00:00, 86.82it/s]\n",
            "Epoch: 5 - Loss: 0.296: 100%|██████████| 11044/11044 [02:05<00:00, 88.18it/s]\n",
            "Epoch: 6 - Loss: 0.279: 100%|██████████| 11044/11044 [02:07<00:00, 86.35it/s]\n",
            "Epoch: 7 - Loss: 0.353: 100%|██████████| 11044/11044 [02:08<00:00, 85.99it/s]\n",
            "Epoch: 8 - Loss: 0.224: 100%|██████████| 11044/11044 [02:06<00:00, 87.60it/s]\n",
            "Epoch: 9 - Loss: 0.282: 100%|██████████| 11044/11044 [02:05<00:00, 87.77it/s]\n",
            "Epoch: 10 - Loss: 0.171: 100%|██████████| 11044/11044 [02:05<00:00, 87.80it/s]\n",
            "Epoch: 11 - Loss: 0.232: 100%|██████████| 11044/11044 [02:08<00:00, 86.07it/s]\n",
            "Epoch: 12 - Loss: 0.113: 100%|██████████| 11044/11044 [02:05<00:00, 88.21it/s]\n",
            "Epoch: 13 - Loss: 0.251: 100%|██████████| 11044/11044 [02:05<00:00, 87.83it/s]\n",
            "Epoch: 14 - Loss: 0.156: 100%|██████████| 11044/11044 [02:05<00:00, 87.74it/s]\n",
            "Epoch: 15 - Loss: 0.213: 100%|██████████| 11044/11044 [02:05<00:00, 88.02it/s]\n",
            "Epoch: 16 - Loss: 0.075: 100%|██████████| 11044/11044 [02:07<00:00, 86.73it/s]\n",
            "Epoch: 17 - Loss: 0.106: 100%|██████████| 11044/11044 [02:06<00:00, 87.51it/s]\n",
            "Epoch: 18 - Loss: 0.119: 100%|██████████| 11044/11044 [02:06<00:00, 87.15it/s]\n",
            "Epoch: 19 - Loss: 0.159: 100%|██████████| 11044/11044 [02:05<00:00, 88.24it/s]\n",
            "Epoch: 20 - Loss: 0.145: 100%|██████████| 11044/11044 [02:08<00:00, 86.18it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.7189506512566501\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAYC-8QCUnMx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}